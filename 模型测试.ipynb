{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Breast: \n",
    "Credit: \n",
    "Leeter：\n",
    "Spam: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置文件验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "hparams = OmegaConf.load('config_Spam.yaml') # 读取配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.max_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams.pro_type_file is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelModule.model5 import VAE5\n",
    "import torch\n",
    "model = VAE5(dim=16, pro_types=pro_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到数据集相关属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "# data_pd = pd.read_csv('Letter_train.csv')\n",
    "# col_names = list(data_pd)\n",
    "# df[col_name].value_counts()\n",
    "# pro_types = [('discrete',16) for _ in col_names]\n",
    "# with open('Letter_pro_type.pkl', 'wb') as f:\n",
    "#     pickle.dump(pro_types, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataModule.dataset1 import FlatDataset, ValidDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = FlatDataset('/root/autodl-tmp/VAE_pytorchLightning/Spam/Spam_without_label.csv', \n",
    "                    pro_type_file='Spam/Spam_pro_type.pkl',\n",
    "                    replace_dict_file='Spam/Spam数值置换表.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValidDataset = ValidDataset(miss_file='Spam/Spam模拟缺失_0_3.csv', \n",
    "                            complete_file='/root/autodl-tmp/VAE_pytorchLightning/Spam/Spam_without_label.csv',\n",
    "                            pro_type_file='Spam/Spam_pro_type.pkl',\n",
    "                            replace_dict_file='Spam/Spam数值置换表.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_dataloader = DataLoader(ValidDataset, \n",
    "                             batch_size=10, \n",
    "                             collate_fn=ValidDataset.collater, \n",
    "                             shuffle=False,\n",
    "                             num_workers=2)\n",
    "val_batch = None\n",
    "for i in valid_dataloader:\n",
    "    val_batch = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0463, 0.0196, 0.0980, 0.0000, 0.0140, 0.0476, 0.0289, 0.0063, 0.0000,\n",
       "        0.0517, 0.0805, 0.0817, 0.1171, 0.0210, 0.0317, 0.0070, 0.0098, 0.0308,\n",
       "        0.1851, 0.0000, 0.1431, 0.0000, 0.0789, 0.0344, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0102, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000, 0.0000, 0.0135, 0.0000, 0.0115, 0.0300, 0.0024,\n",
       "        0.0037, 0.0100, 0.0648])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batch['global_normal'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.6256e-02, 1.9608e-02, 9.9990e+03, 0.0000e+00, 1.5402e-02, 4.7619e-02,\n",
       "        2.8886e-02, 6.3006e-03, 0.0000e+00, 9.9990e+03, 8.0460e-02, 8.1696e-02,\n",
       "        1.1712e-01, 9.9990e+03, 3.1746e-02, 9.9990e+03, 9.9990e+03, 9.9990e+03,\n",
       "        9.9990e+03, 0.0000e+00, 1.4846e-01, 9.9990e+03, 9.9990e+03, 9.9990e+03,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9990e+03, 0.0000e+00,\n",
       "        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.9990e+03, 9.9990e+03, 9.9990e+03,\n",
       "        9.9990e+03, 9.9990e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 9.9990e+03, 9.9990e+03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "        0.0000e+00, 1.3536e-02, 0.0000e+00, 1.1454e-02, 2.9985e-02, 9.9990e+03,\n",
       "        9.9990e+03, 4.8996e-02, 6.4836e-02])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batch['portion_normal'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0., 0., 0.,\n",
       "        0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 1., 1., 1., 1., 1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "        0., 1., 1.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_batch['miss_matrix'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, \n",
    "                             batch_size=10, \n",
    "                             collate_fn=train_dataset.collater, \n",
    "                             shuffle=False,\n",
    "                             num_workers=2)\n",
    "batch = None\n",
    "for i in train_dataloader:\n",
    "    batch = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000e+00, 6.4000e-01, 6.4000e-01, 0.0000e+00, 3.2000e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4000e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 3.2000e-01, 0.0000e+00, 1.2900e+00,\n",
       "         1.9300e+00, 0.0000e+00, 9.6000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 7.7800e-01, 0.0000e+00, 0.0000e+00,\n",
       "         3.7560e+00, 6.1000e+01, 2.7800e+02],\n",
       "        [2.1000e-01, 2.8000e-01, 5.0000e-01, 0.0000e+00, 1.4000e-01, 2.8000e-01,\n",
       "         2.1000e-01, 7.0000e-02, 0.0000e+00, 9.4000e-01, 2.1000e-01, 7.9000e-01,\n",
       "         6.5000e-01, 2.1000e-01, 1.4000e-01, 1.4000e-01, 7.0000e-02, 2.8000e-01,\n",
       "         3.4700e+00, 0.0000e+00, 1.5900e+00, 0.0000e+00, 4.3000e-01, 4.3000e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         7.0000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.3200e-01, 0.0000e+00, 3.7200e-01, 1.8000e-01, 4.8000e-02,\n",
       "         5.1140e+00, 1.0100e+02, 1.0280e+03],\n",
       "        [6.0000e-02, 0.0000e+00, 7.1000e-01, 0.0000e+00, 1.2300e+00, 1.9000e-01,\n",
       "         1.9000e-01, 1.2000e-01, 6.4000e-01, 2.5000e-01, 3.8000e-01, 4.5000e-01,\n",
       "         1.2000e-01, 0.0000e+00, 1.7500e+00, 6.0000e-02, 6.0000e-02, 1.0300e+00,\n",
       "         1.3600e+00, 3.2000e-01, 5.1000e-01, 0.0000e+00, 1.1600e+00, 6.0000e-02,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.0000e-02, 0.0000e+00, 0.0000e+00,\n",
       "         1.2000e-01, 0.0000e+00, 6.0000e-02, 6.0000e-02, 0.0000e+00, 0.0000e+00,\n",
       "         1.0000e-02, 1.4300e-01, 0.0000e+00, 2.7600e-01, 1.8400e-01, 1.0000e-02,\n",
       "         9.8210e+00, 4.8500e+02, 2.2590e+03],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3000e-01, 0.0000e+00,\n",
       "         3.1000e-01, 6.3000e-01, 3.1000e-01, 6.3000e-01, 3.1000e-01, 3.1000e-01,\n",
       "         3.1000e-01, 0.0000e+00, 0.0000e+00, 3.1000e-01, 0.0000e+00, 0.0000e+00,\n",
       "         3.1800e+00, 0.0000e+00, 3.1000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.3700e-01, 0.0000e+00, 1.3700e-01, 0.0000e+00, 0.0000e+00,\n",
       "         3.5370e+00, 4.0000e+01, 1.9100e+02],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3000e-01, 0.0000e+00,\n",
       "         3.1000e-01, 6.3000e-01, 3.1000e-01, 6.3000e-01, 3.1000e-01, 3.1000e-01,\n",
       "         3.1000e-01, 0.0000e+00, 0.0000e+00, 3.1000e-01, 0.0000e+00, 0.0000e+00,\n",
       "         3.1800e+00, 0.0000e+00, 3.1000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.3500e-01, 0.0000e+00, 1.3500e-01, 0.0000e+00, 0.0000e+00,\n",
       "         3.5370e+00, 4.0000e+01, 1.9100e+02],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8500e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.8500e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.2300e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.0000e+00, 1.5000e+01, 5.4000e+01],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.9200e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 6.4000e-01, 9.6000e-01, 1.2800e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 9.6000e-01, 0.0000e+00, 3.2000e-01,\n",
       "         3.8500e+00, 0.0000e+00, 6.4000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 5.4000e-02, 0.0000e+00, 1.6400e-01, 5.4000e-02, 0.0000e+00,\n",
       "         1.6710e+00, 4.0000e+00, 1.1200e+02],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8800e+00, 0.0000e+00,\n",
       "         0.0000e+00, 1.8800e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.0600e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         2.4500e+00, 1.1000e+01, 4.9000e+01],\n",
       "        [1.5000e-01, 0.0000e+00, 4.6000e-01, 0.0000e+00, 6.1000e-01, 0.0000e+00,\n",
       "         3.0000e-01, 0.0000e+00, 9.2000e-01, 7.6000e-01, 7.6000e-01, 9.2000e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5000e-01,\n",
       "         1.2300e+00, 3.5300e+00, 2.0000e+00, 0.0000e+00, 0.0000e+00, 1.5000e-01,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 1.5000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         3.0000e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 2.7100e-01, 0.0000e+00, 1.8100e-01, 2.0300e-01, 2.2000e-02,\n",
       "         9.7440e+00, 4.4500e+02, 1.2570e+03],\n",
       "        [6.0000e-02, 1.2000e-01, 7.7000e-01, 0.0000e+00, 1.9000e-01, 3.2000e-01,\n",
       "         3.8000e-01, 0.0000e+00, 6.0000e-02, 0.0000e+00, 0.0000e+00, 6.4000e-01,\n",
       "         2.5000e-01, 0.0000e+00, 1.2000e-01, 0.0000e+00, 0.0000e+00, 1.2000e-01,\n",
       "         1.6700e+00, 6.0000e-02, 7.1000e-01, 0.0000e+00, 1.9000e-01, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         0.0000e+00, 6.0000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "         4.0000e-02, 3.0000e-02, 0.0000e+00, 2.4400e-01, 8.1000e-02, 0.0000e+00,\n",
       "         1.7290e+00, 4.3000e+01, 7.4900e+02]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['src_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"global_normal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0101e-02, 9.9990e+03, 2.0000e+00, 1.0000e+00, 5.1724e-02, 9.9990e+03,\n",
       "        9.9990e+03, 1.0000e+00, 1.0000e+00, 0.0000e+00, 9.9990e+03, 1.4998e-01,\n",
       "        6.9164e-02, 1.5603e-01, 1.6014e-01, 9.9990e+03, 1.1909e-01, 9.9990e+03,\n",
       "        9.9990e+03, 0.0000e+00, 0.0000e+00, 9.9990e+03, 0.0000e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"portion_normal\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0,10, size=(5,4,3)).float()\n",
    "print(a)\n",
    "f = torch.nn.Softmax(dim=1)\n",
    "f(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0,10,size=(5,12,4)).float()\n",
    "print(a)\n",
    "model = torch.nn.Linear(4,10)\n",
    "model(a[:,1,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(a[:,0].reshape(-1,1,1)).permute(0, 2, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(model, torch.nn.Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0,2,size=(5, 3))\n",
    "b = torch.nn.Parameter(torch.randn(1, 4))\n",
    "print(b)\n",
    "print(a)\n",
    "\n",
    "miss_matric = a.unsqueeze (-1).expand(5,3,4)\n",
    "print(miss_matric)\n",
    "miss_matric*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0,10,size=(5,3)).float()\n",
    "model = torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=1, stride=1)\n",
    "print(a)\n",
    "embedding_out = torch.tensor([])\n",
    "embedding_out = torch.cat((embedding_out, model(a[:,0].reshape(-1,1,1)).permute(0, 2, 1)), dim = 1)\n",
    "embedding_out = torch.cat((embedding_out, model(a[:,1].reshape(-1,1,1)).permute(0, 2, 1)), dim = 1)\n",
    "print(embedding_out.shape)\n",
    "embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型5精度测定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataModule.dataset1 import FlatDataset\n",
    "from modelModule.model5 import VAE5\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "载入成功\n"
     ]
    }
   ],
   "source": [
    "## 模型参数载入\n",
    "model = VAE5(dim=9, \n",
    "            pro_types=pickle.load(open('Breast\\Breast_pro_type.pkl', 'rb')),\n",
    "            replace_dict=pickle.load(open('Breast\\Breast数值置换表.pkl', 'rb')))# nhead=3\n",
    "# checkpoint_path = r'模型参数保存/Credit_Card_model5_norm_way_minmax_norm_/version_1/checkpoints/epoch=31-step=3008.ckpt'    \n",
    "data_norm = 'minmax_norm'  # 数据集采用正则化方式minmax_norm,mean_norm\n",
    "\n",
    "# checkpoint = torch.load(checkpoint_path)\n",
    "# model.load_state_dict({k.replace('model.',''):v for k,v in checkpoint['state_dict'].items()}) \n",
    "# model.eval()\n",
    "\n",
    "print('载入成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss_file = 'Breast\\Breast模拟缺失_0_3.csv'      # 缺失数据集\n",
    "miss_data = pd.read_csv(miss_file)\n",
    "\n",
    "c, _ = model.inference(miss_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(683, 9)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## 模型参数载入\n",
    "# model = VAE5(dim=23, pro_types=pickle.load(open('Credit_Card\\Credit_Card_pro_type.pkl', 'rb'))) # nhead=3\n",
    "# checkpoint_path = r'模型参数保存/Credit_Card_model5_norm_way_minmax_norm_/version_1/checkpoints/epoch=31-step=3008.ckpt'    \n",
    "# data_norm = 'minmax_norm'  # 数据集采用正则化方式minmax_norm,mean_norm\n",
    "# train_csv = r'Credit_Card_model_train.csv'\n",
    "# test_csv = r'Credit_Card_model_test.csv'\n",
    "\n",
    "# checkpoint = torch.load(checkpoint_path)\n",
    "# model.load_state_dict({k.replace('model.',''):v for k,v in checkpoint['state_dict'].items()}) \n",
    "# model.eval()\n",
    "# ## 载入训练集的均值(最小)方差(最大)\n",
    "# train_dataset = FlatDataset(train_csv, data_norm=data_norm, pro_type_file='Credit_Card_pro_type.pkl')\n",
    "# model.get_global_min_max(dataset=train_dataset)\n",
    "# print('载入成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_dataset = FlatDataset(test_csv, data_norm=data_norm, pro_type_file='Credit_Card_pro_type.pkl')\n",
    "# data_size = 10\n",
    "# src_data = np.stack([test_dataset[index]['src_data'] for index in range(data_size)], axis=0)\n",
    "# normal_data = np.stack([test_dataset[index]['global_normal_data'] for index in range(data_size)], axis=0)\n",
    "# portion_normal_data = np.stack([test_dataset[index]['portion_normal_data'] for index in range(data_size)], axis=0)\n",
    "# _, miss_matrix = get_missing(src_data, 0.3) # 得到缺失矩阵\n",
    "# input = portion_normal_data.copy()\n",
    "# input[miss_matrix == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputed_data, output = model.inference(input, miss_matrix) # inference输出的结果已经重构后的结果\n",
    "# imputed_data = M_matrix * miss_data + (1-M_matrix) * imputed_data.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(normal_data[0])\n",
    "# print(output[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_show(src_data, imputed_data, miss_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = FlatDataset('Letter_test.csv', data_norm='mean_norm') # minmax_norm\n",
    "# index = 102\n",
    "# src_data, M_matrix, miss_data = test_dataset[index]['src_data'].reshape(1,-1), test_dataset[index]['global_miss_matrix'].reshape(1,-1), test_dataset[index]['global_miss_data'].reshape(1,-1)\n",
    "# src_data = test_dataset[index]['src_data'].reshape(1,-1)\n",
    "# normal_data = test_dataset[index]['global_normal_data'].reshape(1,-1)\n",
    "# miss_data, M_matrix = get_missing(normal_data, 0.3) # 产生掩码数据，并采用随机数填补\n",
    "\n",
    "# imputed_data, _, _ = model(torch.from_numpy(miss_data).float(), torch.from_numpy(M_matrix).float()) \n",
    "# imputed_data = M_matrix * miss_data + (1-M_matrix) * imputed_data.data.numpy() # 得到最终插补结果,数据由[0,1]范围内\n",
    "# res_imputed_data = np.around(restore_data(imputed_data, test_dataset.Max_Val, test_dataset.Min_Val))\n",
    "# result_show(src_data, res_imputed_data, M_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch测试\n",
    "# src_data, miss_data, M_matrix = batch['src_data'], batch['miss_data'], batch['miss_matrix']\n",
    "# normal_data = batch['normal_data']\n",
    "# imputed_data, _, _ = model(miss_data, M_matrix)\n",
    "# imputed_data = M_matrix * miss_data + (1-M_matrix) * imputed_data.data.numpy()\n",
    "# res_imputed_data = np.around(restore_data(imputed_data, dataset.Max_Val, dataset.Min_Val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12 (main, Apr  5 2022, 06:56:58) \n[GCC 7.5.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9e4dc998ab49a4b372a2babfb22fa4b89464fdfae3cada14d780c018a2464596"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
