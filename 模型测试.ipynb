{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 配置文件验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "hparams = OmegaConf.load('config.yaml') # 读取配置文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hparams.pro_type_file is None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modelModule.model5 import VAE5\n",
    "import torch\n",
    "model = VAE5(dim=16, pro_types=pro_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 得到数据集相关属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "data_pd = pd.read_csv('Letter_train.csv')\n",
    "col_names = list(data_pd)\n",
    "# df[col_name].value_counts()\n",
    "pro_types = [('discrete',16) for _ in col_names]\n",
    "# with open('Letter_pro_type.pkl', 'wb') as f:\n",
    "#     pickle.dump(pro_types, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 0\n",
    "a is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16),\n",
       " ('discrete', 16)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "pro_types = pickle.load(open('Letter_pro_type.pkl', 'rb'))\n",
    "pro_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### dataloader验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataModule.dataset1 import FlatDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = FlatDataset('Letter_train.csv', \n",
    "                    pro_type_file='Letter_pro_type.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(dataset, \n",
    "                             batch_size=10, \n",
    "                             collate_fn=dataset.collater, \n",
    "                             shuffle=True,\n",
    "                             num_workers=2)\n",
    "batch = None\n",
    "for i in train_dataloader:\n",
    "    batch = i\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2667, 0.6000, 0.4000, 0.4000, 0.1333, 0.4667, 0.4667, 0.2000, 0.0000,\n",
       "         0.4667, 0.0000, 0.5333, 0.2000, 0.4667, 0.0667, 0.5333],\n",
       "        [0.1333, 0.4000, 0.1333, 0.2667, 0.0667, 0.0000, 0.0667, 0.3333, 0.4000,\n",
       "         0.0000, 0.0000, 0.4667, 0.0000, 0.5333, 0.0000, 0.5333],\n",
       "        [0.3333, 0.5333, 0.4000, 0.4000, 0.3333, 0.4667, 0.5333, 0.2667, 0.4667,\n",
       "         0.4667, 0.4000, 0.5333, 0.4667, 0.5333, 0.2000, 0.4667],\n",
       "        [0.2000, 0.4667, 0.2000, 0.3333, 0.1333, 0.4667, 0.4667, 0.8667, 0.1333,\n",
       "         0.3333, 0.4000, 0.5333, 0.3333, 0.5333, 0.0000, 0.5333],\n",
       "        [0.2667, 0.4000, 0.4000, 0.6000, 0.4667, 0.6000, 0.6667, 0.4000, 0.2000,\n",
       "         0.4667, 0.4667, 0.4667, 0.4000, 0.7333, 0.4000, 0.3333],\n",
       "        [0.4000, 0.7333, 0.4667, 0.5333, 0.4000, 0.4667, 0.4667, 0.8667, 0.0667,\n",
       "         0.4000, 0.4000, 0.5333, 0.4000, 0.5333, 0.0000, 0.5333],\n",
       "        [0.2667, 0.6000, 0.4000, 0.4000, 0.2667, 0.6000, 0.4667, 0.2667, 0.4000,\n",
       "         0.6000, 0.2667, 0.4667, 0.2000, 0.4667, 0.3333, 0.6667],\n",
       "        [0.3333, 0.6667, 0.5333, 0.4667, 0.6667, 0.6000, 0.4667, 0.2667, 0.2667,\n",
       "         0.4000, 0.4667, 0.5333, 0.5333, 0.5333, 0.4000, 0.4667],\n",
       "        [0.4000, 0.6000, 0.5333, 0.4667, 0.3333, 0.4000, 0.6667, 0.1333, 0.2667,\n",
       "         0.6000, 0.5333, 0.5333, 0.3333, 0.5333, 0.0667, 0.5333],\n",
       "        [0.3333, 0.5333, 0.4667, 0.6667, 0.4667, 0.7333, 0.3333, 0.3333, 0.2667,\n",
       "         0.6000, 0.2000, 0.5333, 0.2000, 0.4000, 0.4000, 0.6000]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch['normal_data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   4,    9,    6,    6,    2,    7,    7,    3, 9999, 9999,    0,    8,\n",
       "         9999, 9999,    1,    8],\n",
       "        [   2,    6,    2,    4,    1, 9999,    1,    5,    6,    0, 9999,    7,\n",
       "            0,    8,    0, 9999],\n",
       "        [   5,    8,    6,    6, 9999,    7, 9999, 9999,    7, 9999, 9999, 9999,\n",
       "            7,    8, 9999,    7],\n",
       "        [9999,    7, 9999, 9999,    2,    7,    7,   13,    2, 9999,    6,    8,\n",
       "            5,    8,    0, 9999],\n",
       "        [   4,    6,    6, 9999, 9999, 9999,   10, 9999, 9999,    7,    7,    7,\n",
       "            6,   11, 9999,    5],\n",
       "        [9999, 9999,    7,    8,    6,    7,    7,   13, 9999,    6,    6,    8,\n",
       "         9999,    8, 9999, 9999],\n",
       "        [   4,    9, 9999, 9999, 9999,    9, 9999,    4,    6, 9999,    4,    7,\n",
       "            3,    7,    5, 9999],\n",
       "        [   5,   10,    8,    7,   10, 9999,    7,    4, 9999,    6,    7,    8,\n",
       "         9999,    8,    6, 9999],\n",
       "        [9999, 9999,    8,    7, 9999, 9999, 9999,    2,    4, 9999,    8,    8,\n",
       "         9999, 9999,    1, 9999],\n",
       "        [   5, 9999,    7,   10,    7,   11,    5,    5,    4, 9999, 9999, 9999,\n",
       "            3,    6, 9999,    9]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"miss_data\"].long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.,  9.,  6.,  6.,  2.,  7.,  7.,  3.,  0.,  7.,  0.,  8.,  3.,  7.,\n",
       "          1.,  8.],\n",
       "        [ 2.,  6.,  2.,  4.,  1.,  0.,  1.,  5.,  6.,  0.,  0.,  7.,  0.,  8.,\n",
       "          0.,  8.],\n",
       "        [ 5.,  8.,  6.,  6.,  5.,  7.,  8.,  4.,  7.,  7.,  6.,  8.,  7.,  8.,\n",
       "          3.,  7.],\n",
       "        [ 3.,  7.,  3.,  5.,  2.,  7.,  7., 13.,  2.,  5.,  6.,  8.,  5.,  8.,\n",
       "          0.,  8.],\n",
       "        [ 4.,  6.,  6.,  9.,  7.,  9., 10.,  6.,  3.,  7.,  7.,  7.,  6., 11.,\n",
       "          6.,  5.],\n",
       "        [ 6., 11.,  7.,  8.,  6.,  7.,  7., 13.,  1.,  6.,  6.,  8.,  6.,  8.,\n",
       "          0.,  8.],\n",
       "        [ 4.,  9.,  6.,  6.,  4.,  9.,  7.,  4.,  6.,  9.,  4.,  7.,  3.,  7.,\n",
       "          5., 10.],\n",
       "        [ 5., 10.,  8.,  7., 10.,  9.,  7.,  4.,  4.,  6.,  7.,  8.,  8.,  8.,\n",
       "          6.,  7.],\n",
       "        [ 6.,  9.,  8.,  7.,  5.,  6., 10.,  2.,  4.,  9.,  8.,  8.,  5.,  8.,\n",
       "          1.,  8.],\n",
       "        [ 5.,  8.,  7., 10.,  7., 11.,  5.,  5.,  4.,  9.,  3.,  8.,  3.,  6.,\n",
       "          6.,  9.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"src_data\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = imputed_data * global_max + global_min # 广播效应"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0,10, size=(5,4,3)).float()\n",
    "print(a)\n",
    "f = torch.nn.Softmax(dim=1)\n",
    "f(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0,10,size=(5,12,4)).float()\n",
    "print(a)\n",
    "model = torch.nn.Linear(4,10)\n",
    "model(a[:,1,:]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[:,0].reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(a[:,0].reshape(-1,1,1)).permute(0, 2, 1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(model, torch.nn.Embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0,2,size=(5, 3))\n",
    "b = torch.nn.Parameter(torch.randn(1, 4))\n",
    "print(b)\n",
    "print(a)\n",
    "\n",
    "miss_matric = a.unsqueeze (-1).expand(5,3,4)\n",
    "print(miss_matric)\n",
    "miss_matric*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.randint(0,10,size=(5,3)).float()\n",
    "model = torch.nn.Conv1d(in_channels=1, out_channels=8, kernel_size=1, stride=1)\n",
    "print(a)\n",
    "embedding_out = torch.tensor([])\n",
    "embedding_out = torch.cat((embedding_out, model(a[:,0].reshape(-1,1,1)).permute(0, 2, 1)), dim = 1)\n",
    "embedding_out = torch.cat((embedding_out, model(a[:,1].reshape(-1,1,1)).permute(0, 2, 1)), dim = 1)\n",
    "print(embedding_out.shape)\n",
    "embedding_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型精度测定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataModule.dataset1 import FlatDataset\n",
    "# from modelModule.model1 import VAE\n",
    "# from modelModule.model2 import VAE2\n",
    "from modelModule.model4 import VAE4\n",
    "from torch.utils.data import DataLoader\n",
    "from utils import result_show, get_missing\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 模型参数载入\n",
    "model = VAE4(dim=23) # nhead=3\n",
    "checkpoint_path = r'模型参数保存/Credit_model4_norm_way_mean_norm_/version_1/checkpoints/epoch=38-step=936.ckpt'    \n",
    "data_norm = 'mean_norm'  # 数据集采用正则化方式minmax_norm,mean_norm\n",
    "train_csv = r'Credit_Card_test.csv'\n",
    "test_csv = r'Credit_Card_test.csv'\n",
    "\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model.load_state_dict({k.replace('model.',''):v for k,v in checkpoint['state_dict'].items()}) \n",
    "model.eval()\n",
    "## 载入训练集的均值(最小)方差(最大)\n",
    "train_dataset = FlatDataset(train_csv, data_norm=data_norm)\n",
    "model.get_global_min_max(global_max=train_dataset.Max_Val, global_min=train_dataset.Min_Val)\n",
    "print('载入成功')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = FlatDataset(test_csv, data_norm=data_norm)\n",
    "data_size = 10\n",
    "src_data = np.stack([test_dataset[index]['src_data'] for index in range(data_size)], axis=0)\n",
    "normal_data = np.stack([test_dataset[index]['global_normal_data'] for index in range(data_size)], axis=0)\n",
    "_, miss_matrix = get_missing(src_data, 0.3) # 得到缺失矩阵\n",
    "input = src_data.copy()\n",
    "input[miss_matrix == 0] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data, output = model.inference(input, miss_matrix) # inference输出的结果已经重构后的结果\n",
    "# imputed_data = M_matrix * miss_data + (1-M_matrix) * imputed_data.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(23):\n",
    "    print(src_data[0][i], '————', imputed_data[0][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_show(src_data, imputed_data, miss_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputed_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dataset = FlatDataset('Letter_test.csv', data_norm='mean_norm') # minmax_norm\n",
    "# index = 102\n",
    "# src_data, M_matrix, miss_data = test_dataset[index]['src_data'].reshape(1,-1), test_dataset[index]['global_miss_matrix'].reshape(1,-1), test_dataset[index]['global_miss_data'].reshape(1,-1)\n",
    "# src_data = test_dataset[index]['src_data'].reshape(1,-1)\n",
    "# normal_data = test_dataset[index]['global_normal_data'].reshape(1,-1)\n",
    "# miss_data, M_matrix = get_missing(normal_data, 0.3) # 产生掩码数据，并采用随机数填补\n",
    "\n",
    "# imputed_data, _, _ = model(torch.from_numpy(miss_data).float(), torch.from_numpy(M_matrix).float()) \n",
    "# imputed_data = M_matrix * miss_data + (1-M_matrix) * imputed_data.data.numpy() # 得到最终插补结果,数据由[0,1]范围内\n",
    "# res_imputed_data = np.around(restore_data(imputed_data, test_dataset.Max_Val, test_dataset.Min_Val))\n",
    "# result_show(src_data, res_imputed_data, M_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch测试\n",
    "# src_data, miss_data, M_matrix = batch['src_data'], batch['miss_data'], batch['miss_matrix']\n",
    "# normal_data = batch['normal_data']\n",
    "# imputed_data, _, _ = model(miss_data, M_matrix)\n",
    "# imputed_data = M_matrix * miss_data + (1-M_matrix) * imputed_data.data.numpy()\n",
    "# res_imputed_data = np.around(restore_data(imputed_data, dataset.Max_Val, dataset.Min_Val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
